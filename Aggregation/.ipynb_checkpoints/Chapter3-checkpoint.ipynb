{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHAPTER3 - PAC-BAYESIAN BOUNDS FOR ONLINE LEARNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notations**\n",
    "\n",
    "Fix $f_1,\\dots,f_M$ and as in Chapter 2, $f(\\cdot)=(f_1(\\cdot),\\dots,f_M(\\cdot))$. We will possibly consider all types of aggregation (MS, C and L). Let $[(x_t,y_t)]_{t\\in\\mathbb{N}^*}$ be any sequence in $(\\mathcal{X}\\times[-B_y,B_y])^{\\mathbb{N}^*}$. We don't have to know exactly the range of $y$, but we have to know an upper bound: $B>0$ such that $B_y\\leq B$. In this case, for any $\\alpha\\in\\mathbb{R}^M$ it makes sense to define the predictor $f_{\\alpha}(\\cdot) = [\\left<\\alpha,f(\\cdot)\\right>]_B $ where $[u]_B$ is $-B$ if $u\\leq -B$, $B$ if $u\\geq B$ and $u$ otherwise (clip function). We put $\\mathcal{F}=\\{f_\\alpha,\\alpha\\in\\mathbb{R}^M\\}$. Finally, any loss function $\\ell$ such that $\\forall t$, $\\ell(y_t,\\cdot)$ is a convex function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponentially Weighted Aggregation (EWA)**\n",
    "\n",
    "Initialization: fix $p_1 = \\pi$ an arbitrary probability distribution on $\\mathbb{R}^M$ (equiped with the Borel $\\sigma$-algebra) and let $\\eta>0$.\n",
    "\n",
    "Step $t$: $\\hat{y}_t=\\int f_\\theta (x_t) p_t({\\rm d})\\theta$ and once $y_t$ is revealed,\n",
    "$$ p_{t+1}({\\rm d}\\theta) = \\frac{\n",
    "\\exp\\left(-\\eta \\ell(y_t,f_\\theta (x_t)) \\right) p_{t}({\\rm d}\\theta)\n",
    "}{\n",
    "\\int_{\\mathbb{R}^M} \\exp\\left(-\\eta \\ell(y_t,f_\\alpha (x_t)) \\right) p_{t}({\\rm d}\\alpha)\n",
    "}. $$\n",
    "\n",
    "_Remark_: by recurrence we also have\n",
    "$$ p_t({\\rm d}\\theta) = \\frac{\\exp\\left(-\\eta \\sum_{i=1}^{t-1}\\ell(y_i,f_\\theta (x_i)) \\right) \\pi({\\rm d}\\theta) }\n",
    "{\\int \\exp\\left(-\\eta \\sum_{i=1}^{t-1}\\ell(y_i,f_\\alpha (x_i)) \\right) \\pi({\\rm d}\\alpha)} =\n",
    " \\frac{\\exp\\left(-\\eta \\sum_{i=1}^{t-1}\\ell(y_i,f_\\theta (x_i)) \\right) \\pi({\\rm d}\\theta) }\n",
    "{W_t}  $$\n",
    "where we introduce the notation $W_t$ for short.\n",
    "\n",
    "_Remark 2_: in the case where the support of $\\pi$ is finite, the implementation of this method is trivial, we only have to update a finite number of weights at each step. However, in the general case, the implementation of EWA  is far from trivial, we will discuss this point in Chapter 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theoretical analysis of EWA**\n",
    "\n",
    "A reminder: the Kullback-Leibler divergence between two probability measures $\\mathcal{K}(\\mu,\\nu)=\\int \\log\\left( \\frac{{\\rm d}\\mu}{{\\rm d}\\nu}(\\theta)\\right)\\mu({\\rm d}\\theta) $ if $\\mu\\ll\\nu$ and $\\mathcal{K}(\\mu,\\nu)=+\\infty$ otherwise. Note that this it does not satisfy the definition of a distance, however we have $\\mathcal{K}(\\mu,\\nu)\\Leftrightarrow \\mu=\\nu$ and $\\mathcal{K}(\\mu,\\nu)\\geq 4\\|\\mu-\\nu\\|_{{\\rm TV}}^2 $ (Pinsker's inequality).\n",
    "\n",
    "_Theorem_:\n",
    "\n",
    "1) Assume that $\\forall t$, $\\forall u\\in[-B,B]$, $\\ell(y_t,u)\\leq C$  (bounded loss function). Then for any $T\\geq 1$,\n",
    "$$\n",
    "L_T \\leq \\inf_{\\rho}\\left\\{ \\int \\sum_{t=1}^T \\ell(y_t,f_{\\theta}(x_t)) \\rho({\\rm d}\\theta)\n",
    "       + \\frac{C^2 T\\eta}{8} + \\frac{\\mathcal{K}(\\rho,\\pi)}{\\eta} \\right\\}\n",
    "$$\n",
    "where the infimum is over all probability measures $\\rho$.\n",
    "\n",
    "2) Under the same assumption (bounded loss function),\n",
    "$$\n",
    "L_T \\leq \\frac{C\\eta}{1-\\exp(-C\\eta)} \\inf_{\\rho}\\left\\{ \\int \\sum_{t=1}^T \\ell(y_t,f_{\\theta}(x_t)) \\rho({\\rm d}\\theta)\n",
    "       + \\frac{\\mathcal{K}(\\rho,\\pi)}{\\eta} \\right\\}.\n",
    "$$\n",
    "\n",
    "3) Finally, assume that $\\eta$ and $\\ell$ are such that $\\forall t$, $\\eta \\ell(y_t,\\cdot)$ is exp-convex on $[-B,B]$ (that means that $\\exp(-\\ell(y_t,\\cdot))$ is concave. Then:\n",
    "$$\n",
    "L_T \\leq \\inf_{\\rho}\\left\\{ \\int \\sum_{t=1}^T \\ell(y_t,f_{\\theta}(x_t)) \\rho({\\rm d}\\theta)\n",
    "       + \\frac{\\mathcal{K}(\\rho,\\pi)}{\\eta} \\right\\}.\n",
    "$$\n",
    "\n",
    "Comments are in order! First: in 1) and 2) there is no restriction on $\\eta$. However, 3) requires a stringent assumption that usually implies restriction on $\\eta$. For example, simple calculus shows that when $\\ell(y,u)=|y-u|$, the exp-convexity assumption is never satisfied while, when $\\ell(y,u)=(y-u)^2$ it is satisfied iff $\\eta \\leq \\frac{1}{8B^2} $. Then, in order to understand the full power of these results, we provide a few simple applications. The proof is given at the end of the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS-type aggregation**\n",
    "\n",
    "In this case, we are only interested in the predictors $f_1$ to $f_M$. So, let us introduce the canonical basis of $\\mathbb{R}^M$, say $e_1,\\dots,e_M$ and take $\\pi$ as uniform on the set $\\{e_1,\\dots,e_M\\}$. Then, for any $i\\in\\{1,\\dots,M\\}$, setting $\\rho=\\delta_{e_i}$ leads to $\\mathcal{K}(\\rho,\\pi)=\\log(M)$ and $ \\int \\sum_{t=1}^T \\ell(y_t,f_{\\theta}(x_t)) \\rho({\\rm d}\\theta) =  \\sum_{t=1}^T \\ell(y_t,f_{i}(x_t))$. So 1) leads to:\n",
    "$$\n",
    "L_T \\leq \\inf_{1\\leq i\\leq M} \\sum_{t=1}^T \\ell(y_t,f_{i}(x_t) + \\frac{C^2 T\\eta}{8} + \\frac{\\log(M)}{\\eta}\n",
    "$$\n",
    "and taking $\\eta=2\\sqrt{\\frac{2\\log(M)}{T C^2}}$ leads to a regret in\n",
    "$$\n",
    "\\mathcal{R}_T(\\{f_1,\\dots,f_M\\}) \\leq C \\sqrt{\\frac{T \\log(M)}{2}}.\n",
    "$$\n",
    "So the regret is in $\\sqrt{T\\log(M)}$. This is a nice result. However, in Chapter 1, in the realizable case, we obtained with the halving algorithm a regret that does not depend on $T$. We can here mimic this, using 2). Actually, in the realizable case, 2) leads to\n",
    "$$\n",
    "L_T \\leq  \\frac{C\\eta}{1-\\exp(-C\\eta)} \\left\\{  \\underbrace{\\inf_{1\\leq i\\leq M} \\sum_{t=1}^T \\ell(y_t,f_{i}(x_t)}_{=0}\n",
    "       + \\frac{\\log(M)}{\\eta} \\right\\}\n",
    "$$\n",
    "and set, for example, $\\eta=\\frac{1}{C}$ to get:\n",
    "$$\n",
    "L_T \\leq  \\frac{C\\log(M)}{1-\\frac{1}{{\\rm e}}}\n",
    "$$\n",
    "that is, a regret that does not depend on $T$. However, note that in the general case, 2) is seen as quite weak as it does not lead to a bound on the regret - that's because $\\frac{C\\eta}{1-\\exp(-C\\eta)}>1$. Finally, _if we work with the squared loss_, 3) with $\\eta=\\frac{1}{8B^2}$ leads to\n",
    "$$\n",
    "\\mathcal{R}_T(\\{f_1,\\dots,f_M\\}) \\leq 8B^2 \\log(M).\n",
    "$$\n",
    "So, the result provided by 3) is much stronger than the one provided by 1) and 2), but, once again, it requires stronger assumptions.\n",
    "\n",
    "Finally, note that using the quadratic loss the online-to-batch trick of the previous chapter, we can define $\\hat{f}(\\cdot)= \\frac{1}{n}\\sum_{i=1}^n \\int f_{\\theta}(\\cdot) p_t({\\rm d}\\theta) $ and this leads to:\n",
    "$$ \\mathbb{E}[R(\\hat{f})] \\leq \\inf_{1\\leq i\\leq M} R(f_i) + \\frac{8B^2\\log(M)}{n}. $$\n",
    "The estimator $\\hat{f}$ is known under the name progressive mixture rule. It is known that the rate $\\log(M)/n$ cannot be improved in this case.\n",
    "\n",
    "We now illustrate the performance of the online EWA on the same example as in Chapter 1. Remind the setting: $\\mathcal{X}=\\{0,\\dots,N-1\\}$, $\\mathcal{F}=(f_0,\\dots,f_{M-1})$ where the $f_i$ will be drawn i.i.d from the set of all functions $\\{0,\\dots,N-1\\}\\rightarrow\\{-1,+1\\}$. We consider the absolute loss $\\ell(u,v)=|u-v|$. However, this time, we do not consider the realizable case: a function $i_0$ is chosen randomly, but then for all $t$, $y_t = f_{i_0}(x_t)$ with probability $1-p$ and $y_t = - f_{i_0}(x_t)$ with probability $p$, you can choose $p$ as you want between $0$ and $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 20\n",
    "M = 500\n",
    "T = 500\n",
    "p = 0.15\n",
    "eta = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare EWA to a random guess, and to the function $f_{i_0}$ (which is not available in practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zapfack/tools/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/zapfack/tools/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: DeprecationWarning: non integer (and non boolean) array-likes will not be accepted as indices in the future\n",
      "/home/zapfack/tools/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:16: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/zapfack/tools/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:19: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAETCAYAAADOPorfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhhjPGaZhzHGGI9Z5mGMMcZj/w8kvMbeuU7CKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a0878cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import *\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = floor(rand(T)*N)\n",
    "f = sign(randn(M,N))\n",
    "iO = floor(rand()*M)\n",
    "y = f[iO,[x]][0]*((rand(T)>p)-0.5)*2\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "\n",
    "pure_rand,EWA,fiO,WMA = [],[],[],[]\n",
    "w = repeat(1.0/M,M)\n",
    "for t in range(T):\n",
    "    pred = f[:,x[t]]\n",
    "    error = abs(y[t]-pred)\n",
    "    list.append(EWA,abs(y[t]-sum(w*pred)))\n",
    "    list.append(fiO,abs(y[t]-pred[iO]))\n",
    "    w = w*exp(-eta*error)\n",
    "    w = w/sum(w)\n",
    "\n",
    "pure_rand = cumsum((sign(randn(T))+1))\n",
    "EWA = cumsum(EWA)\n",
    "fiO = cumsum(fiO)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.ylim(0,1.2*T)\n",
    "l1, = plt.plot(EWA)\n",
    "l2, = plt.plot(pure_rand)\n",
    "l3, = plt.plot(fiO)\n",
    "plt.legend([l1,l2,l3],['EWA','purely random','$i_0$'])\n",
    "plt.grid(True,which=\"both\")\n",
    "plt.xlabel(r\"Time step $t$\")\n",
    "plt.ylabel(r\"Cumulated absolute loss $L_t$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L-type aggregation (with quadratic loss)**\n",
    "\n",
    "Define $\\pi=\\mathcal{N}(0,\\sigma^2 I_M)$. Then, for $\\rho=\\mathcal{N}(\\theta_0,S^2 I_M)$, calculations show that\n",
    "$$\n",
    "\\mathcal{K}(\\rho,\\pi) = \\frac{1}{2}\\left\\{M\\left[\\frac{S^2}{\\sigma^2}-1+\\log\\left(\\frac{\\sigma^2}{S^2}\\right) \\right]+\\frac{\\|\\theta_0\\|^2}{\\sigma^2}\\right\\}.\n",
    "$$\n",
    "Then, if we assume that $\\|f_i\\|_\\infty \\leq C_f$ for any $i$, then we also can get the upper bound:\n",
    "$$\n",
    "\\int \\sum_{t=1}^T (y_t - f_\\theta (x_t))^2 \\rho({\\rm d}\\theta) \\leq \\sum_{t=1}^T (y_t - f_{\\theta_0} (x_t))^2 + T M^2 S^2 C_f^2.\n",
    "$$\n",
    "Plugging this in 3), putting $S^2 = \\frac{1}{TM^2}$, $\\sigma^2=1$, and taking $\\eta=\\frac{1}{8B^2}$, and few rough upper bounds lead to:\n",
    "$$\n",
    "L_T \\leq \\inf_{\\theta_0 \\in \\mathbb{R}^M }\\left\\{\n",
    " \\sum_{t=1}^T (y_t - f_{\\theta_0} (x_t))^2 + 4B^2 M \\log\\left( \\frac{TM \\sigma^2}{{\\rm e}}\\right) + C_f^2 + \\frac{1+\\|\\theta_0\\|^2}{\\sigma^2}\n",
    "\\right\\}\n",
    "$$\n",
    "or to a regret bound on a ball with radius $r$:\n",
    "$$\n",
    "\\mathcal{R}_T(\\{f_{\\theta}\\in\\mathcal{F},\\|\\theta\\|\\leq r\\}) \\leq\n",
    "4B^2 M \\log\\left( \\frac{TM \\sigma^2}{{\\rm e}}\\right) + C_f^2 + \\frac{1+r^2}{\\sigma^2}.\n",
    "$$\n",
    "Note that the dependence in $r$ can be improved using a heavy-tailed distribution for $\\pi$; the dependence in $M$ and $T$ cannot be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof of the theorem**\n",
    "\n",
    "_Lemma_: for any bounded function $h$ define $\\pi_h$ by $\\pi_h({\\rm d}\\theta) = \\frac{\\exp[h(\\theta)]\\pi({\\rm d}\\theta)}\n",
    "   {\\int \\exp[h(\\alpha)]\\pi({\\rm d}\\alpha)}$. Then:\n",
    "$$ \\sup_{\\rho}\\left[\\int h{\\rm d}\\rho - \\mathcal{K}(\\rho,\\pi)\\right] = \\log \\int \\exp[h(\\theta)] \\pi({\\rm d}\\theta) $$\n",
    "and the infimum is reached for $\\rho=\\pi_h$.\n",
    "\n",
    "_Proof of the lemma_: calculate $\\mathcal{K}(\\rho,\\pi_h)$ and use the fact that this is minimal, and null, for $\\rho=\\pi_h$.\n",
    "\n",
    "_Proof of the theorem_: the proof of 1), 2) and 3) rely on the same idea: first, we upper bound\n",
    "$$ \\prod_{t=1}^T \\int \\exp\\left(-\\eta \\ell(y_t,f_{\\theta}(x_t))\\right) p_t({\\rm d}\\theta)$$\n",
    "in terms of\n",
    "$$ \\prod_{t=1}^T  \\exp\\left(-\\eta \\int \\ell(y_t,f_{\\theta}(x_t)) p_t({\\rm d}\\theta) \\right). $$\n",
    "More precisely, we seek for a one-to-one function $F$ such that\n",
    "$$\n",
    " \\prod_{t=1}^T \\int \\exp\\left(-\\eta \\ell(y_t,f_{\\theta}(x_t))\\right) p_t({\\rm d}\\theta)\n",
    "\\leq F\\left\\{ \\prod_{t=1}^T  \\exp\\left(-\\eta \\int \\ell(y_t,f_{\\theta}(x_t)) p_t({\\rm d}\\theta) \\right) \\right\\}.\n",
    "$$\n",
    "Why? Well, it's all we need to do the job! First note that by Jensen's inequality:\n",
    "$$\n",
    "\\prod_{t=1}^T  \\exp\\left(-\\eta \\int \\ell(y_t,f_{\\theta}(x_t)) p_t({\\rm d}\\theta) \\right)\n",
    "= \\exp\\left(-\\eta \\sum_{t=1}^T \\int \\ell(y_t,f_{\\theta}(x_t)) p_t({\\rm d}\\theta) \\right)\n",
    "\\leq \\exp\\left(-\\eta \\sum_{t=1}^T  \\ell(y_t,\\hat{y}_t) \\right) = \\exp(-\\eta L_T) .\n",
    "$$\n",
    "On the other hand:\n",
    "$$\n",
    "\\prod_{t=1}^T \\int \\exp\\left(-\\eta \\ell(y_t,f_{\\theta}(x_t))\\right) p_t({\\rm d}\\theta)\n",
    "= \\prod_{t=1}^T \\int \\frac{\\exp\\left(-\\eta \\ell(y_t,f_{\\theta}(x_t))\\right) \\exp\\left(-\\eta \\sum_{i=1}^{t-1} \\ell(y_i,f_{\\theta}(x_i))\\right)}{W_t} \\pi({\\rm d}\\theta) = \\prod_{t=1}^T \\frac{W_{t+1}}{W_t} = W_{T+1}\n",
    "$$\n",
    "and thanks to the lemma,\n",
    "$$\n",
    "W_{T+1} = \\int \\exp\\left(-\\eta \\sum_{t=1}^T \\ell(y_t,f_{\\theta}(x_t)) \\right) \\pi({\\rm d}\\theta)\n",
    " = \\exp\\left[\n",
    "   -\\eta \\inf_{\\rho } \\left( \\int \\sum_{t=1}^T \\ell(y_t,f_{\\theta}(x_t)) \\rho({\\rm d}\\theta) +\n",
    "     \\frac{\\mathcal{K}(\\rho,\\pi)}{\\eta}\\right)\n",
    " \\right].\n",
    "$$\n",
    "So, if we actually manage to find the desired function $F$ we obtain:\n",
    "$$\n",
    "L_T \\leq \\frac{-1}{\\eta} \\log F^{-1} \\left\\{ \\exp\\left[\n",
    "  -\\eta \\inf_{\\rho } \\left( \\int \\sum_{t=1}^T \\ell(y_t,f_{\\theta}(x_t)) \\rho({\\rm d}\\theta) +\n",
    "     \\frac{\\mathcal{K}(\\rho,\\pi)}{\\eta}\\right)\n",
    " \\right]\\right\\}.\n",
    "$$\n",
    "\n",
    "For 1), use Hoeffding inequality to get:\n",
    "$$ \\prod_{t=1}^T \\int \\exp\\left(-\\eta \\ell(y_t,f_{\\theta}(x_t))\\right) p_t({\\rm d}\\theta)\n",
    "\\leq \\prod_{t=1}^T  \\exp\\left(-\\eta \\int \\ell(y_t,f_{\\theta}(x_t)) p_t({\\rm d}\\theta) + \\frac{C^2\\eta^2}{8} \\right). $$\n",
    "Finally, for 2), use the basic inequality $\\mathbb{E}(\\exp(sZ)) \\leq \\exp\\left[ \\frac{\\exp(sc)-1}{c} \\mathbb{E}(Z)\\right] $ for any random variable $Z$ with values in $[0,c]$ to get:\n",
    "$$ \\prod_{t=1}^T \\int \\exp\\left(-\\eta \\ell(y_t,f_{\\theta}(x_t))\\right) p_t({\\rm d}\\theta)\n",
    "\\leq \\prod_{t=1}^T  \\exp\\left( -\\eta \\frac{1-\\exp(-C \\eta)}{C\\eta } \\int \\ell(y_t,f_{\\theta}(x_t)) p_t({\\rm d}\\theta)\\right). $$\n",
    "Finally, for 3), the bound:\n",
    "$$ \\prod_{t=1}^T \\int \\exp\\left(-\\eta \\ell(y_t,f_{\\theta}(x_t))\\right) p_t({\\rm d}\\theta)\n",
    "\\leq \\exp(-\\eta L_T) $$\n",
    "holds immediately thanks to the exp-convexity assumption!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "Most of these results are presented in:\n",
    "\n",
    "N. Cesa-Bianchi & G. Lugosi, _Prediction, Learning and Games_, Cambridge (2006).\n",
    "\n",
    "This book very good and, as usual with these authors, so well written that it's very enjoyable to read it completely, even if only Chapters 1 to 4 are related to the present material. However, the whole book focuses on what is called here MS-type aggregation: there is a finite number of predictors. The general case is covered, for example, in the first chapter of the following PhD thesis:\n",
    "\n",
    "S. Gerchinovitz, _Prediction of Individual Sequences and Prediction in the Statistical Framework: some Links around Sparse Regression and Aggregation Techniques_, PhD thesis - Université Paris Sud (2011).\n",
    "\n",
    "Note that the idea of EWA is due to two nice papers, one by Vovk, and the other Littlestone and Warmuth (the exact reference is provided in the book _Prediction, Learning and Games_ for example). Finally, the progressive mixture rule was introduced by O. Catoni, the reference is provided in the next chapter. The optimality of the rate $\\log(M)/n$ is due to Tsybakov:\n",
    "\n",
    "A. Tsybakov, Optimal Rates of Aggregation, in _Learning Theory and Kernel Machines_, Springer Lecture Notes in Computer Science 2777, pp. 303-313 (2003).\n",
    "\n",
    "However, since then, it was proven that this estimator suffers many drawbacks, and many improvements were proposed by Catoni, notably by J.-Y. Audibert and many Tsybakov's PhD student: G. Lécué, P. Rigollet, P. Bellec, but this goes beyond the scope of this course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
