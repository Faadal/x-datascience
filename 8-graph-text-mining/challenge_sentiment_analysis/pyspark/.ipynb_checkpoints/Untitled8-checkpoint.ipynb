{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/train/pos11538_7.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"./data/train/pos\"+pos[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Felix Unger (Jack Lemmon) has just been dumped by his wife, because he is one of the most annoying , neurotic people in the world. Suicide is his way out, but he just can\\'t seem to get it to work, so he heads over to his friends house. Oscar Madison (Walther Matthau) is also recently divorced and living it up in bachelor heaven. Smoking, gambling, hitting on chicks, eating out and never cleaning is paradise to him. Well, with the suicide attempts Oscar decides to let Felix move in. At first, it is a match made in heaven, Felix cooks and cleans and helps Oscar pay his alimony on time, but soon Oscar is jonesing for women and Felix (who in today\\'s world would probably be gay) isn\\'t ready to move on. They invite a couple of British birds over and they find Felix so tender that soon they and Felix are weeping and chatting about his family life, leaving Oscar denied. This is it, he explodes and throws him out, but Felix isn\\'t as helpless as it seems, and soon he has the upper hand. My favorite quote \"You leave me little notes on my pillow. Told you 158 times I can\\'t stand little notes on my pillow. \"We\\'re all out of cornflakes. F.U.\" Took me three hours to figure out F.U. was Felix Ungar!\" Based on a Neil Simon play (who also wrote the screenplay), this has a certain theatre feel to it. Set and the repartee and looks feel quite play-like (for better or worse). Lemmon and Mathau have excellent comedic chemistry and have appeared in the Grumpier Old Men movies and Out to Sea, reprising the same finicky/slob roles, but with different names (to avoid royalty issues, I\\'m sure).<br /><br />This movie is like strawberries dipped in chocolate. The chocolate is smooth, sweet and rich, the strawberry is tart, juicy and bright red (unless you get those nasty greenish ones). They are almost polar opposites, but together, the contrasts highlight each other and make a wonderful dessert. 7/10 <br /><br />http://blog.myspace.com/locoformovies'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "txt1 = \"i characters characters really fucking love that movie. I enjoyed the charaters play and so on. looking forward a movie like that .... \"\n",
    "txt2 = \"It was so annoying. i hate that type of movie :(\"\n",
    "rootdirPOS =\"./data/train/pos\"\n",
    "rootdirNEG =\"./data/train/neg\"\n",
    "pos = os.listdir(\"./data/train/pos\")\n",
    "neg = os.listdir(\"./data/train/neg\")\n",
    "data = []\n",
    "for i in range(1):\n",
    "    with open(\"./data/train/pos/\"+pos[i], 'r') as content_file:\n",
    "        content = content_file.read();\n",
    "        data.append(content)\n",
    "    with open(\"./data/train/neg/\"+neg[i], 'r') as content_file:\n",
    "        content = content_file.read();\n",
    "        data.append(content)\n",
    "    \n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#topwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doc2words(doc):\n",
    "\tstop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "\t\t\t\t'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "                'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "                'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "                'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "                'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "                'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "                'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "                'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "                'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "                'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "                'than', 'too', 'very', 's', 't', 'can','could', 'will','would', 'just', 'don', 'should', 'now','films',\n",
    "                'film','movies','movie','br','http','also', ' ', '']\n",
    "\t\n",
    " \tstop_words = ['br','http','film','films','movie','movies','also','',' ']\n",
    "\tstop_words.extend([w.encode('ascii','ignore') for w in stopwords.words(\"english\")])\n",
    "\t\n",
    "\t#print stop_words\n",
    "\t# Remove punctuation and lowercase\n",
    "\tpunctuation = set(string.punctuation)\n",
    "\tfor w in ['.',',','--',':','!','?','(',')','\"','/','<','>',\"'s\",\"'t\",\"'m\",\"'re\"]:\n",
    "\t\tdoc=doc.replace(w,' ')\n",
    "\twords=set(doc.strip().split(' '))\n",
    "\twords = [w.lower() for w in words]\n",
    "\tbigrams = zip(words,words[1:])\n",
    "\ttrigrams = zip(words,words[1:],words[2:]) \n",
    "\tstop_words.extend(punctuation) \n",
    "\tstop_words.extend([w for w in words if len(w)<3])\n",
    "\tstop_words = list(set(stop_words))\n",
    "\t#grams = words.extend([\" \".join(gram) for gram in bigrams if not any(i in stop_words for i in gram)])\n",
    "\tbigrams = [\" \".join(gram) for gram in bigrams if not any(i in stop_words for i in gram)]\n",
    "\ttrigrams = [\" \".join(gram) for gram in trigrams if not any(i in stop_words for i in gram)]\n",
    "\twords = [w for w in words if w not in stop_words and w not in punctuation]\n",
    "\t#words = [w for w in words if len(w)>2]\n",
    "\twords.extend(bigrams)\n",
    "\twords.extend(trigrams)\n",
    "\n",
    "\t#return bigrams[a],any(i in stop_words for i in bigrams[a])\n",
    "\treturn words\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-b57705e07093>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print \"-\".join(b)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# print \"******************\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc2words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-a118806f21b7>\u001b[0m in \u001b[0;36mdoc2words\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mbad_words\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mstop_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#grams = words.extend([\" \".join(gram) for gram in bigrams if not any(i in stop_words for i in gram)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mbigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgram\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbigrams\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbad_words\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mtrigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgram\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrigrams\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbad_words\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbad_words\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-a118806f21b7>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((i,))\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mbad_words\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mstop_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#grams = words.extend([\" \".join(gram) for gram in bigrams if not any(i in stop_words for i in gram)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mbigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgram\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbigrams\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbad_words\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mtrigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgram\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrigrams\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbad_words\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbad_words\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "# print data[0]\n",
    "# print \"******************\"\n",
    "# a,b,c = doc2words(data[0])\n",
    "# print \" \".join(a)\n",
    "# print \"******************\"\n",
    "# print \"-\".join(b)\n",
    "# print \"******************\"\n",
    "print \"-\".join(doc2words(data[1]))\n",
    "set(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " grams = words.extend([gram for gram in grams if not any(i in gram)])\n",
    "\tgrams = [gram for gram in grams if not any(i in gram)]\n",
    "\t#words = [w.lower() for w in words if w not in punctuation and w not in stop_words]\n",
    "\twords = [w.lower() for w in words if w not in stop_words and w not in punctuation]\n",
    "\twords = [w for w in words if not any(i in w for i in ['/','<','>'])]\n",
    "\t# # Stemming\n",
    "\tstemmer = PorterStemmer()\n",
    "\twords = [stemmer.stem(unicode(w, \"utf-8\")) for w in words] \n",
    "\t#print len(words)\n",
    "\treturn list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing cosine...\n",
      "this is a foo bar\n",
      "this is a foo bar\n",
      "cosine = 1.0\n",
      "\n",
      "this is a foo bar\n",
      "foo bar bar black sheep\n",
      "cosine = 0.507092552837\n",
      "\n",
      "this is a foo bar\n",
      "this is a sentence\n",
      "cosine = 0.67082039325\n",
      "\n",
      "foo bar bar black sheep\n",
      "this is a foo bar\n",
      "cosine = 0.507092552837\n",
      "\n",
      "foo bar bar black sheep\n",
      "foo bar bar black sheep\n",
      "cosine = 1.0\n",
      "\n",
      "foo bar bar black sheep\n",
      "this is a sentence\n",
      "cosine = 0.0\n",
      "\n",
      "this is a sentence\n",
      "this is a foo bar\n",
      "cosine = 0.67082039325\n",
      "\n",
      "this is a sentence\n",
      "foo bar bar black sheep\n",
      "cosine = 0.0\n",
      "\n",
      "this is a sentence\n",
      "this is a sentence\n",
      "cosine = 1.0\n",
      "\n",
      "\n",
      "Testing ngrams...\n",
      "this is a foo bar\n",
      "[('this', 'is'), ('is', 'a'), ('a', 'foo'), ('foo', 'bar')]\n",
      "[('this', 'is', 'a'), ('is', 'a', 'foo'), ('a', 'foo', 'bar')]\n",
      "\n",
      "foo bar bar black sheep\n",
      "[('foo', 'bar'), ('bar', 'bar'), ('bar', 'black'), ('black', 'sheep')]\n",
      "[('foo', 'bar', 'bar'), ('bar', 'bar', 'black'), ('bar', 'black', 'sheep')]\n",
      "\n",
      "this is a sentence\n",
      "[('this', 'is'), ('is', 'a'), ('a', 'sentence')]\n",
      "[('this', 'is', 'a'), ('is', 'a', 'sentence')]\n",
      "\n",
      "\n",
      "Testing tfidf...\n",
      "[('this is a foo bar', [1, 1, 0, 1, 1, 0, 0, 1]), ('foo bar bar black sheep', [0, 2, 1, 1, 0, 0, 1, 0]), ('this is a sentence', [1, 0, 0, 0, 1, 1, 0, 1])]\n",
      "['a', 'bar', 'black', 'foo', 'is', 'sentence', 'sheep', 'this']\n",
      "[[0.30000000000000004, 0.30000000000000004, 0.0, 0.30000000000000004, 0.30000000000000004, 0.0, 0.0, 0.30000000000000004], [0.0, 0.6000000000000001, 0.6000000000000001, 0.30000000000000004, 0.0, 0.0, 0.6000000000000001, 0.0], [0.375, 0.0, 0.0, 0.0, 0.375, 0.75, 0.0, 0.375]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt, log\n",
    "from itertools import chain, product\n",
    "from collections import defaultdict\n",
    "\n",
    "def cosine_sim(u,v):\n",
    "    return np.dot(u,v) / (sqrt(np.dot(u,u)) * sqrt(np.dot(v,v)))\n",
    "\n",
    "def ngrams(sentence, n):\n",
    "  return zip(*[sentence.split()[i:] for i in range(n)])\n",
    "\n",
    "def tfidf(corpus, vocab):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "\n",
    "    corpus = [('this is a foo bar', [1, 1, 0, 1, 1, 0, 0, 1]), \n",
    "    ('foo bar bar black sheep', [0, 2, 1, 1, 0, 0, 1, 0]), \n",
    "    ('this is a sentence', [1, 0, 0, 0, 1, 1, 0, 1])]\n",
    "\n",
    "    vocab = ['a', 'bar', 'black', 'foo', 'is', 'sentence', \n",
    "    'sheep', 'this']\n",
    "\n",
    "    OUTPUT:\n",
    "\n",
    "    [[0.300, 0.300, 0.0, 0.300, 0.300, 0.0, 0.0, 0.300], \n",
    "    [0.0, 0.600, 0.600, 0.300, 0.0, 0.0, 0.600, 0.0], \n",
    "    [0.375, 0.0, 0.0, 0.0, 0.375, 0.75, 0.0, 0.375]]\n",
    "\n",
    "    \"\"\"\n",
    "    def termfreq(matrix, doc, term):\n",
    "        try: return matrix[doc][term] / float(sum(matrix[doc].values()))\n",
    "        except ZeroDivisionError: return 0\n",
    "    def inversedocfreq(matrix, term):\n",
    "        try: \n",
    "            return float(len(matrix)) /sum([1 for i,_ in enumerate(matrix) if matrix[i][term] > 0])\n",
    "        except ZeroDivisionError: return 0\n",
    "\n",
    "    matrix = [{k:v for k,v in zip(vocab, i[1])} for i in corpus]\n",
    "    tfidf = defaultdict(dict)\n",
    "    for doc,_ in enumerate(matrix):\n",
    "        for term in matrix[doc]:\n",
    "            tf = termfreq(matrix,doc,term)\n",
    "            idf = inversedocfreq(matrix, term)\n",
    "            tfidf[doc][term] = tf*idf\n",
    "\n",
    "    return [[tfidf[doc][term] for term in vocab] for doc,_ in enumerate(tfidf)]\n",
    "\n",
    "\n",
    "def corpus2vectors(corpus):\n",
    "    def vectorize(sentence, vocab):\n",
    "        return [sentence.split().count(i) for i in vocab]\n",
    "    vectorized_corpus = []\n",
    "    vocab = sorted(set(chain(*[i.lower().split() for i in corpus])))\n",
    "    for i in corpus:\n",
    "        vectorized_corpus.append((i, vectorize(i, vocab)))\n",
    "    return vectorized_corpus, vocab\n",
    "\n",
    "def create_test_corpus():\n",
    "    sent1 = \"this is a foo bar\"\n",
    "    sent2 = \"foo bar bar black sheep\"\n",
    "    sent3 = \"this is a sentence\"\n",
    "\n",
    "    all_sents = [sent1,sent2,sent3]\n",
    "    corpus, vocab = corpus2vectors(all_sents)\n",
    "    return corpus, vocab\n",
    "\n",
    "def test_cosine():\n",
    "    corpus, vocab = create_test_corpus()\n",
    "\n",
    "    for sentx, senty in product(corpus, corpus):\n",
    "        print sentx[0]\n",
    "        print senty[0]\n",
    "        print \"cosine =\", cosine_sim(sentx[1], senty[1])\n",
    "        print\n",
    "\n",
    "def test_ngrams():\n",
    "    corpus, vocab = create_test_corpus()\n",
    "    for sentx in corpus:\n",
    "        print sentx[0]\n",
    "        print ngrams(sentx[0],2)\n",
    "        print ngrams(sentx[0],3)\n",
    "        print\n",
    "\n",
    "def test_tfidf():\n",
    "    corpus, vocab = create_test_corpus()\n",
    "    print corpus\n",
    "    print vocab\n",
    "    print tfidf(corpus, vocab)\n",
    "\n",
    "print \"Testing cosine...\"\n",
    "test_cosine()\n",
    "print\n",
    "print \"Testing ngrams...\"\n",
    "test_ngrams()\n",
    "print\n",
    "print \"Testing tfidf...\"\n",
    "test_tfidf()\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_list = ['this', 'is', 'a', 'good', 'book']\n",
    "def find_bigrams(input_list):\n",
    "    return zip(input_list,input_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('this', 'is'), ('is', 'a'), ('a', 'good'), ('good', 'book')]\n"
     ]
    }
   ],
   "source": [
    "print find_bigrams(input_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_trigrams(input_list):\n",
    "    return zip(input_list,input_list[1:], input_list[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('this', 'is', 'a'), ('is', 'a', 'good'), ('a', 'good', 'book')]\n"
     ]
    }
   ],
   "source": [
    "print find_trigrams(input_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def find_ngrams(input_list,n):\n",
    "    return zip(*[input_list[i:] for i in range (n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "find_trigrams() takes exactly 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3b984234d1d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfind_trigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: find_trigrams() takes exactly 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "n=2\n",
    "find_trigrams(input_list,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
