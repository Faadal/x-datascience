{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Challenge : Prediction of stock market Volume\n",
    "By <i>Fabrice ZAPFACK</i> & <i>Basile CALDERAN</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainOutPut=pd.read_csv('data/challenge_output_data_training_file_prediction_of'\n",
    "                      '_transaction_volumes_in_financial_markets.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv('data/training_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDF = pd.read_csv('data/testing_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF['date']=pd.to_datetime(trainDF['date'],unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDF['date']=pd.to_datetime(testDF['date'],unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF['year'] = trainDF['date'].dt.year\n",
    "trainDF['month'] = trainDF['date'].dt.month\n",
    "trainDF['day'] = trainDF['date'].dt.day\n",
    "trainDF['weekday'] = trainDF['date'].dt.weekday\n",
    "trainDF['week'] = trainDF['date'].dt.week\n",
    "trainDF['n_days'] = trainDF['date'].apply(lambda date: (date - pd.to_datetime(\"1970-01-01\")).days)\n",
    "        \n",
    "trainDF = trainDF.join(pd.get_dummies(trainDF['year'], prefix='y'))\n",
    "trainDF = trainDF.join(pd.get_dummies(trainDF['month'], prefix='m'))\n",
    "trainDF = trainDF.join(pd.get_dummies(trainDF['day'], prefix='d'))\n",
    "trainDF = trainDF.join(pd.get_dummies(trainDF['weekday'], prefix='wd'))\n",
    "trainDF = trainDF.join(pd.get_dummies(trainDF['week'], prefix='w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDF['year'] = testDF['date'].dt.year\n",
    "testDF['month'] = testDF['date'].dt.month\n",
    "testDF['day'] = testDF['date'].dt.day\n",
    "testDF['weekday'] = testDF['date'].dt.weekday\n",
    "testDF['week'] = testDF['date'].dt.week\n",
    "testDF['n_days'] = testDF['date'].apply(lambda date: (date - pd.to_datetime(\"1970-01-01\")).days)\n",
    "        \n",
    "testDF = testDF.join(pd.get_dummies(testDF['year'], prefix='y'))\n",
    "testDF = testDF.join(pd.get_dummies(testDF['month'], prefix='m'))\n",
    "testDF = testDF.join(pd.get_dummies(testDF['day'], prefix='d'))\n",
    "testDF = testDF.join(pd.get_dummies(testDF['weekday'], prefix='wd'))\n",
    "testDF = testDF.join(pd.get_dummies(testDF['week'], prefix='w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF=trainDF.drop([\"year\",'month','day','weekday','week'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDF=testDF.drop([\"year\",'month','day','weekday','week'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF2=trainDF.drop([\"ID\",'date','product_id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testDF=testDF.sort_values(by=[\"ID\"],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idsFrame=testDF['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    618557\n",
       "1    618558\n",
       "2    618559\n",
       "3    618560\n",
       "4    618561\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idsFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDF2=testDF.drop([\"ID\",'date','product_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF2[trainDF2<0]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDF2[testDF2<0]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613220, 164)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(trainDF2.shape[0]):\n",
    "    if np.isnan(trainDF2.iloc[i,:]).sum()/53>=0.8:\n",
    "        trainDF2.loc[i,:]=trainDF2.mean()\n",
    "trainDF2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614098, 164)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(testDF2.shape[0]):\n",
    "    if np.isnan(testDF2.iloc[i,:]).sum()/53>=0.8:\n",
    "        testDF2.loc[i,:]=testDF2.mean()\n",
    "testDF2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "InterpolTrain=trainDF2.interpolate(method='linear',limit_direction='both',limit=10000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Interpol=pd.concat([trainOutPut[\"ID\"],InterpolTrain],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "InterpolTest=testDF2.interpolate(method='linear',limit_direction='both',limit=100000, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FinalInterpol=pd.merge(Interpol,trainOutPut,on=[\"ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention : ici pour submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresTrain = InterpolTrain.drop(['09:30:00'], axis=1)\n",
    "#featuresTrain = InterpolTrain\n",
    "featuresTest =  InterpolTest.drop(['09:30:00'], axis=1)\n",
    "X_train = featuresTrain.values\n",
    "y_train = trainOutPut['TARGET'].values\n",
    "X_test = featuresTest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(613220, 163)\n",
      "(613220,)\n",
      "(614098, 163)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:90.964347\n",
      "[1]\ttrain-error:82.795686\n",
      "[2]\ttrain-error:75.411004\n",
      "[3]\ttrain-error:68.726921\n",
      "[4]\ttrain-error:62.676269\n",
      "[5]\ttrain-error:57.189232\n",
      "[6]\ttrain-error:52.209294\n",
      "[7]\ttrain-error:47.685689\n",
      "[8]\ttrain-error:43.573239\n",
      "[9]\ttrain-error:39.831725\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "param ={}  \n",
    "param['objective'] = 'reg:linear'\n",
    "param['eta'] = 0.09\n",
    "param['max_depth'] = 100\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "xg_train = xgb.DMatrix( X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_test)\n",
    "\n",
    "def evalerror(preds,xg_train):\n",
    "    y_test = xg_train.get_label()\n",
    "    return 'error',  np.mean(np.abs((preds-y_test ) / y_test)) * 100\n",
    "\n",
    "\n",
    "watchlist = [ (xg_train,'train') ]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist ,feval=evalerror);\n",
    "#bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# get prediction\n",
    "y_pred = bst.predict( xg_test );\n",
    "#print np.mean(np.abs((y_pred-y_test ) / y_test)) * 100\n",
    "#nround = 50\n",
    "#bst = xgb(param=param, data = X_train, label = y_train, nrounds=nround)\n",
    "#y_pred = bst.predict( xg_test );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outFrame=pd.DataFrame(y_pred, columns=['TARGET'])\n",
    "outFrame=pd.concat([idsFrame, outFrame], axis=1)\n",
    "outFrame.to_csv('out.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention : ici pour test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=0)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "param ={}  \n",
    "param['objective'] = 'reg:linear'\n",
    "param['eta'] = 0.09\n",
    "param['max_depth'] = 100\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "xg_train = xgb.DMatrix( X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "def evalerror(preds,xg_train):\n",
    "    y_test = xg_train.get_label()\n",
    "    return 'error',  np.mean(np.abs((preds-y_test ) / y_test)) * 100\n",
    "\n",
    "\n",
    "watchlist = [ (xg_train,'train') ]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist ,feval=evalerror);\n",
    "#bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# get prediction\n",
    "y_pred = bst.predict( xg_test );\n",
    "#print np.mean(np.abs((y_pred-y_test ) / y_test)) * 100\n",
    "#nround = 50\n",
    "#bst = xgb(param=param, data = X_train, label = y_train, nrounds=nround)\n",
    "#y_pred = bst.predict( xg_test );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(np.abs((y_pred-y_test ) / y_test)) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
